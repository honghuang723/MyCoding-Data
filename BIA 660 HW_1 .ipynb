{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>HW 1: Preprocess documents using Python</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-block alert-warning\">Each assignment needs to be completed independently. Never ever copy others' work (even with minor modification, e.g. changing variable names). Anti-Plagiarism software will be used to check all submissions. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you need to define two functions and a class to analyze an article. A sample article is provided for testing. In general, your code should be able to analyze any article. \n",
    "\n",
    "Overall, through this assignment, you are expect to:\n",
    "\n",
    "- Learn how to define functions and classes\n",
    "- Take the first step in NLP: tokenization and token analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Define a function to tokenize a document \n",
    "\n",
    "Please be sure to `complete all the steps` as listed below.\n",
    "\n",
    "\n",
    " - Define a function named `tokenize(doc)` as follows:\n",
    "     * take `doc` (a string) as an input argument\n",
    "     * split `doc` into tokens by any space, including  ` `(space), `\\t` (tab), or  `\\n` (newline).\n",
    "     * remove all leading or trailing spaces from each token. \n",
    "     * remove all leading or training punctuations from each token. However, it is fine to have punctuations in the middle of a token (e.g., life-saving, didn't).\n",
    "     * remove empty tokens or tokens that have only one character (e.g. `I`) \n",
    "     * convert all tokens into the lower case\n",
    "     * count the frequency of each remaining tokens. Save the result into a dictionary to store each token and its count as a key-value pair.\n",
    "     * return the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "9, 11\n"
     ]
    }
   ],
   "source": [
    "# hint1: If needed, you can use the following to retrieve the list of punctions\n",
    "\n",
    "import string\n",
    "print(string.punctuation)\n",
    "\n",
    "# hint 2: you can use the following to remove leading or trailing punctuations from a token\n",
    "token = '(9, 11).'\n",
    "print(token.strip(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    \n",
    "    voc = {}\n",
    "        \n",
    "    # add your code here\n",
    "    doc=doc.split(' ')\n",
    "    x=[]\n",
    "    for i in doc:\n",
    "        a=i.strip()\n",
    "        a=a.strip(string.punctuation)\n",
    "        a=a.lower()\n",
    "        if a != '' and len(a)>1:\n",
    "            if not a in voc:\n",
    "                voc[a] = 1\n",
    "            else:\n",
    "                voc[a] = voc[a] + 1\n",
    "        x.append(a)\n",
    "\n",
    "    return voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'what': 1, 'investors': 1, 'don’t': 1, 'like': 1, 'is': 2, 'uncertainty': 1, 'said': 1, 'jason': 1, 'draho': 1, 'head': 1, 'of': 4, 'asset': 1, 'allocation': 1, 'americas': 1, 'at': 3, 'ubs': 1, 'global': 1, 'wealth': 1, 'management': 1, 'in': 4, 'phone': 1, 'interview': 1, 'pointing': 1, 'to': 1, 'selloff': 1, 'that’s': 1, 'left': 1, 'few': 1, 'corners': 1, 'financial': 1, 'markets': 1, 'unscathed': 1, 'january': 1, 'even': 1, 'with': 1, 'sharp': 1, 'rally': 1, 'late': 1, 'friday': 1, 'the': 2, 'interest': 1, 'rate-sensitive': 1, 'nasdaq': 1, 'composite': 1, 'index': 2, 'comp': 1, '3.13': 1, 'remained': 1, 'correction': 1, 'territory': 1, 'defined': 1, 'as': 1, 'fall': 1, 'least': 2, '10': 1, 'from': 2, 'its': 2, 'most': 1, 'recent': 1, 'record': 1, 'close': 1, 'worse': 1, 'russell': 1, '2000': 1, 'small-capitalization': 1, 'stocks': 1, 'rut': 1, '1.93': 1, 'bear': 1, 'market': 1, 'down': 1, '20': 1, 'nov': 1, 'peak': 1}\n"
     ]
    }
   ],
   "source": [
    "# the text is from https://www.marketwatch.com/story/what-to-expect-from-markets-in-the-next-six-weeks-before-the-federal-reserve-revamps-its-easy-money-stance-11643457817\n",
    "\n",
    "doc ='''\"What investors don’t like is uncertainty,\" said Jason Draho, \n",
    "        head of asset allocation Americas at UBS Global Wealth Management, \n",
    "        in a phone interview, pointing to a selloff that’s left \n",
    "        few corners of financial markets unscathed in January.\n",
    "\n",
    "        Even with a sharp rally late Friday, the interest rate-sensitive Nasdaq \n",
    "        Composite Index COMP, +3.13% remained in correction territory, defined \n",
    "        as a fall of at least 10% from its most recent record close. Worse, \n",
    "        the Russell 2000 index of small-capitalization stocks RUT, +1.93% is \n",
    "        in a bear market, down at least 20% from its Nov. 8 peak.\n",
    "    '''\n",
    "\n",
    "print(tokenize(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Analyze Document Sentiment \n",
    "\n",
    "\n",
    " - Define a function named `get_sentiment(doc, positives, negatives)` as follows:\n",
    "     * take three input arguments:\n",
    "         - `doc` (a string) as an input \n",
    "         - `positives`: a list of positive words\n",
    "         - `negatives`: a list of negative words\n",
    "     * call the function in Q1 to get the token dictionary\n",
    "     * find `unique tokens` that are within `positives` and `negatives` respectively\n",
    "     * return the following:\n",
    "         - the positive and negative tokens found in this document\n",
    "         - an `overall sentiment score` calculated as follows:\n",
    "             - `1` if `doc` has `more` unique positive tokens than negative tokens, \n",
    "             - `0` if `doc` has an `equal` number of unique positive and negative tokens \n",
    "             - `-1` if `doc` has `less` unique positive tokens than negative tokens,\n",
    "\n",
    "\n",
    "To test your function, please use the provided files for positive and negative words. See the sample code for how to retrieve these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(doc, positives, negatives):\n",
    "    \n",
    "    pos = []\n",
    "    neg = []\n",
    "    sentiment = None\n",
    "    \n",
    "    # add your code here\n",
    "    i= tokenize(doc)\n",
    "\n",
    "    a = positives\n",
    "    b = negatives\n",
    "    \n",
    "    pos = [c for c in i if c in a]\n",
    "    neg = [d for d in i if d in b]\n",
    "\n",
    "    pos_num = len(pos)\n",
    "    neg_num = len(neg)\n",
    "    \n",
    "    grade = pos_num - neg_num\n",
    "    \n",
    "    if grade > 0:\n",
    "        sentiment = 1\n",
    "    elif grade == 0:\n",
    "        sentiment = 0\n",
    "    elif grade < 0 :\n",
    "        sentiment = -1\n",
    "        \n",
    "    \n",
    "    return pos, neg, sentiment  \n",
    "    return pos, neg, sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the list of positive/negative words\n",
    "\n",
    "positives = open(\"positive-words.txt\").read().split()\n",
    "negatives = open(\"negative-words.txt\").read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['like', 'sharp'], ['fall', 'worse', 'rut'], -1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc ='''\"What investors don’t like is uncertainty,\" said Jason Draho, \n",
    "        head of asset allocation Americas at UBS Global Wealth Management, \n",
    "        in a phone interview, pointing to a selloff that’s left \n",
    "        few corners of financial markets unscathed in January.\n",
    "\n",
    "        Even with a sharp rally late Friday, the interest rate-sensitive Nasdaq \n",
    "        Composite Index COMP, +3.13% remained in correction territory, defined \n",
    "        as a fall of at least 10% from its most recent record close. Worse, \n",
    "        the Russell 2000 index of small-capitalization stocks RUT, +1.93% is \n",
    "        in a bear market, down at least 20% from its Nov. 8 peak.\n",
    "    '''\n",
    "\n",
    "get_sentiment(doc, positives, negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Define a class to analyze a document \n",
    "\n",
    "\n",
    " - Define a new class called `Analyzer` as follows: \n",
    " \n",
    "    - It has two attributes:\n",
    "        - `text`: store the document text \n",
    "        - `vocab`: a dictionary to store the count of each token  \n",
    "  \n",
    "    - It has an `__init__` function which \n",
    "       - takes `doc`, a document (i.e. a string) as an input, and save `doc` into `text` attribute\n",
    "       - calls the `tokenize` function that you defined in Q1 with `doc` as the input, and save the returned dictionary to `vocab` attribute \n",
    "\n",
    "    - It has a function named `sentiment(postives, negatives)` which \n",
    "        - calls `get_sentiment` function you defined in Q2 to analyze the `text` attribute with the supplied `positives` and `negatives` word lists\n",
    "        - returns an overall sentiment score\n",
    "\n",
    "    - It has a function named `topN` which \n",
    "        - takes a number `N` as an input\n",
    "        - finds the most frequent `N` words and their counts in the document\n",
    "        - returns the top `N` words and their counts as a list of tuples\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**:\n",
    "\n",
    "- What words are frequent? Are you able to get a good idea about the article based on the frequent words? \n",
    "\n",
    "- Do you think your function can accurately tell the sentiment of a document? What are potential problems of this method?\n",
    "\n",
    "Write your analysis as a pdf file and submit to Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer(object):\n",
    "\n",
    "    # add your code here\n",
    "    def __init__(self, doc):\n",
    "        self.text = doc\n",
    "        self.text = tokenize(doc)\n",
    "        self.vocab = self.text\n",
    "    \n",
    "    def sentiment(self, postives, negatives):\n",
    "        postives,negatives,sentiment = get_sentiment(doc, positives, negatives)\n",
    "        return sentiment\n",
    "    \n",
    "    def topN(self, N): \n",
    "        \n",
    "        from collections import OrderedDict\n",
    "        voc = tokenize(doc)\n",
    "        sorted_num = OrderedDict(sorted(voc.items(), key=lambda k:k[1],reverse=True))\n",
    "\n",
    "\n",
    "        a=[]\n",
    "        for z in sorted_num:\n",
    "            if sorted_num[z] >= N:\n",
    "                a.append(z)\n",
    "                a.append(sorted_num[z])\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: \n",
      " {'what': 1, 'investors': 1, 'don’t': 1, 'like': 1, 'is': 2, 'uncertainty': 1, 'said': 1, 'jason': 1, 'draho': 1, 'head': 1, 'of': 4, 'asset': 1, 'allocation': 1, 'americas': 1, 'at': 3, 'ubs': 1, 'global': 1, 'wealth': 1, 'management': 1, 'in': 4, 'phone': 1, 'interview': 1, 'pointing': 1, 'to': 1, 'selloff': 1, 'that’s': 1, 'left': 1, 'few': 1, 'corners': 1, 'financial': 1, 'markets': 1, 'unscathed': 1, 'january': 1, 'even': 1, 'with': 1, 'sharp': 1, 'rally': 1, 'late': 1, 'friday': 1, 'the': 2, 'interest': 1, 'rate-sensitive': 1, 'nasdaq': 1, 'composite': 1, 'index': 2, 'comp': 1, '3.13': 1, 'remained': 1, 'correction': 1, 'territory': 1, 'defined': 1, 'as': 1, 'fall': 1, 'least': 2, '10': 1, 'from': 2, 'its': 2, 'most': 1, 'recent': 1, 'record': 1, 'close': 1, 'worse': 1, 'russell': 1, '2000': 1, 'small-capitalization': 1, 'stocks': 1, 'rut': 1, '1.93': 1, 'bear': 1, 'market': 1, 'down': 1, '20': 1, 'nov': 1, 'peak': 1} \n",
      "\n",
      "Sentiment:  -1 \n",
      "\n",
      "Top 3 words:  ['of', 4, 'in', 4, 'at', 3]\n"
     ]
    }
   ],
   "source": [
    "# Code to test your class\n",
    "\n",
    "positives = open(\"positive-words.txt\").read().split()\n",
    "negatives = open(\"negative-words.txt\").read().split()\n",
    "\n",
    "\n",
    "doc ='''\"What investors don’t like is uncertainty,\" said Jason Draho, \n",
    "        head of asset allocation Americas at UBS Global Wealth Management, \n",
    "        in a phone interview, pointing to a selloff that’s left \n",
    "        few corners of financial markets unscathed in January.\n",
    "\n",
    "        Even with a sharp rally late Friday, the interest rate-sensitive Nasdaq \n",
    "        Composite Index COMP, +3.13% remained in correction territory, defined \n",
    "        as a fall of at least 10% from its most recent record close. Worse, \n",
    "        the Russell 2000 index of small-capitalization stocks RUT, +1.93% is \n",
    "        in a bear market, down at least 20% from its Nov. 8 peak.\n",
    "    '''\n",
    "analyzer = Analyzer(doc)\n",
    "\n",
    "print(\"Vocabulary: \\n\", analyzer.vocab, \"\\n\")\n",
    "print(\"Sentiment: \", analyzer.sentiment(positives, negatives), \"\\n\")\n",
    "print(\"Top 3 words: \",analyzer.topN(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. (Bonus) Sentiment Analysis \n",
    "\n",
    "In Q3, you implemented a simple sentiment analysis method based on a set of annotated sentiment words. Carefully observe the result, could you identify at least two issues of this method? Could you think of ways to correct these issues?\n",
    "\n",
    "- Write your analysis in a pdf file.\n",
    "\n",
    "- Write a function `improve_sentiment(doc, positives, negatives)` to implement your ideas to improve this function.\n",
    "\n",
    "\n",
    "Note, `Q4 is optional`. If you complete it, you can earn extra credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_sentiment(doc, positives, negatives):\n",
    "    \n",
    "    pos = []\n",
    "    neg = []\n",
    "    sentiment = None\n",
    "    \n",
    "    # add your code here\n",
    "    \n",
    "    \n",
    "    return pos, neg, sentiment    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Guideline\n",
    "- Following the solution template provided below. Use __main__ block to test your functions and class\n",
    "- Save your code into a python file (e.g. assign1.py) that can be run in a python 3 environment. Please ensure your filename does not have any space. In Jupyter Notebook, you can export notebook as .py file in menu \"File->Download as\".\n",
    "- Make sure you have all import statements. To test your code:\n",
    "    - Open a command window \n",
    "    - Go to the folder where you solution is stored (i.e. `cd <your folder>`\n",
    "    - Type `python <your solution file>` to see if it can run successfully.\n",
    "- For more details, check assignment submission guideline on Canvas\n",
    "\n",
    "\n",
    "**Good Luck!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Question 1\n",
      "{'what': 1, 'investors': 1, 'don’t': 1, 'like': 1, 'is': 2, 'uncertainty': 1, 'said': 1, 'jason': 1, 'draho': 1, 'head': 1, 'of': 4, 'asset': 1, 'allocation': 1, 'americas': 1, 'at': 3, 'ubs': 1, 'global': 1, 'wealth': 1, 'management': 1, 'in': 4, 'phone': 1, 'interview': 1, 'pointing': 1, 'to': 1, 'selloff': 1, 'that’s': 1, 'left': 1, 'few': 1, 'corners': 1, 'financial': 1, 'markets': 1, 'unscathed': 1, 'january': 1, 'even': 1, 'with': 1, 'sharp': 1, 'rally': 1, 'late': 1, 'friday': 1, 'the': 2, 'interest': 1, 'rate-sensitive': 1, 'nasdaq': 1, 'composite': 1, 'index': 2, 'comp': 1, '3.13': 1, 'remained': 1, 'correction': 1, 'territory': 1, 'defined': 1, 'as': 1, 'fall': 1, 'least': 2, '10': 1, 'from': 2, 'its': 2, 'most': 1, 'recent': 1, 'record': 1, 'close': 1, 'worse': 1, 'russell': 1, '2000': 1, 'small-capitalization': 1, 'stocks': 1, 'rut': 1, '1.93': 1, 'bear': 1, 'market': 1, 'down': 1, '20': 1, 'nov': 1, 'peak': 1}\n",
      "\n",
      "Test Question 2\n",
      "(['like', 'sharp'], ['fall', 'worse', 'rut'], -1)\n",
      "\n",
      "Test Question 3\n",
      "Vocabulary: \n",
      " {'what': 1, 'investors': 1, 'don’t': 1, 'like': 1, 'is': 2, 'uncertainty': 1, 'said': 1, 'jason': 1, 'draho': 1, 'head': 1, 'of': 4, 'asset': 1, 'allocation': 1, 'americas': 1, 'at': 3, 'ubs': 1, 'global': 1, 'wealth': 1, 'management': 1, 'in': 4, 'phone': 1, 'interview': 1, 'pointing': 1, 'to': 1, 'selloff': 1, 'that’s': 1, 'left': 1, 'few': 1, 'corners': 1, 'financial': 1, 'markets': 1, 'unscathed': 1, 'january': 1, 'even': 1, 'with': 1, 'sharp': 1, 'rally': 1, 'late': 1, 'friday': 1, 'the': 2, 'interest': 1, 'rate-sensitive': 1, 'nasdaq': 1, 'composite': 1, 'index': 2, 'comp': 1, '3.13': 1, 'remained': 1, 'correction': 1, 'territory': 1, 'defined': 1, 'as': 1, 'fall': 1, 'least': 2, '10': 1, 'from': 2, 'its': 2, 'most': 1, 'recent': 1, 'record': 1, 'close': 1, 'worse': 1, 'russell': 1, '2000': 1, 'small-capitalization': 1, 'stocks': 1, 'rut': 1, '1.93': 1, 'bear': 1, 'market': 1, 'down': 1, '20': 1, 'nov': 1, 'peak': 1} \n",
      "\n",
      "Sentiment:  -1 \n",
      "\n",
      "Top 3 words:  ['of', 4, 'in', 4, 'at', 3]\n"
     ]
    }
   ],
   "source": [
    "# Structure of your solution to Assignment 1 \n",
    "\n",
    "import string\n",
    "\n",
    "# define your function and class here\n",
    "\n",
    "# best practice to test your class\n",
    "# if your script is exported as a module,\n",
    "# the following part is ignored\n",
    "# this is equivalent to main() in Java\n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Test Question 1\n",
    "    doc ='''\"What investors don’t like is uncertainty,\" said Jason Draho, \n",
    "        head of asset allocation Americas at UBS Global Wealth Management, \n",
    "        in a phone interview, pointing to a selloff that’s left \n",
    "        few corners of financial markets unscathed in January.\n",
    "\n",
    "        Even with a sharp rally late Friday, the interest rate-sensitive Nasdaq \n",
    "        Composite Index COMP, +3.13% remained in correction territory, defined \n",
    "        as a fall of at least 10% from its most recent record close. Worse, \n",
    "        the Russell 2000 index of small-capitalization stocks RUT, +1.93% is \n",
    "        in a bear market, down at least 20% from its Nov. 8 peak.\n",
    "    '''\n",
    "\n",
    "    print(\"Test Question 1\")\n",
    "    print(tokenize(doc))\n",
    "    \n",
    "    print(\"\\nTest Question 2\")\n",
    "    print(get_sentiment(doc, positives, negatives))\n",
    "    \n",
    "    # Test Question 2\n",
    "    print(\"\\nTest Question 3\")\n",
    "    \n",
    "    analyzer = Analyzer(doc)\n",
    "\n",
    "    print(\"Vocabulary: \\n\", analyzer.vocab, \"\\n\")\n",
    "    print(\"Sentiment: \", analyzer.sentiment(positives, negatives), \"\\n\")\n",
    "    print(\"Top 3 words: \",analyzer.topN(3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):    \n",
    "    voc = {}\n",
    "\n",
    "    doc=doc.split(' ')\n",
    "    x=[]\n",
    "    for i in doc:\n",
    "        a=i.strip()\n",
    "        a=a.strip(string.punctuation)\n",
    "        a=a.lower()\n",
    "        if a != '' and len(a)>1:\n",
    "            if not a in voc:\n",
    "                voc[a] = 1\n",
    "            else:\n",
    "                voc[a] = voc[a] + 1\n",
    "        x.append(a)\n",
    "\n",
    "    return voc\n",
    "\n",
    "def get_sentiment(doc, positives, negatives):\n",
    "    \n",
    "    pos = []\n",
    "    neg = []\n",
    "    sentiment = None\n",
    "    \n",
    "    # add your code here\n",
    "    i= tokenize(doc)\n",
    "\n",
    "    a = positives\n",
    "    b = negatives\n",
    "    \n",
    "    pos = [c for c in i if c in a]\n",
    "    neg = [d for d in i if d in b]\n",
    "\n",
    "    pos_num = len(pos)\n",
    "    neg_num = len(neg)\n",
    "    \n",
    "    sentiment = pos_num - neg_num\n",
    "    \n",
    "    return pos, neg, sentiment\n",
    "\n",
    "class Analyzer(object):\n",
    "\n",
    "    # add your code here\n",
    "    def __init__(self, doc):\n",
    "        self.text = doc\n",
    "        self.text = tokenize(doc)\n",
    "        self.vocab = self.text\n",
    "    \n",
    "    def sentiment(self, postives, negatives):\n",
    "        postives,negatives,sentiment = get_sentiment(doc, positives, negatives)\n",
    "        return sentiment\n",
    "    \n",
    "    def topN(self, N): \n",
    "        \n",
    "        from collections import OrderedDict\n",
    "        voc = tokenize(doc)\n",
    "        sorted_num = OrderedDict(sorted(voc.items(), key=lambda k:k[1],reverse=True))\n",
    "\n",
    "\n",
    "        a=[]\n",
    "        for z in sorted_num:\n",
    "            if sorted_num[z] >= N:\n",
    "                a.append(z)\n",
    "                a.append(sorted_num[z])\n",
    "        return a\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
